<!DOCTYPE html>
<html lang="en">
  <head>
    
      <title>理解MapReduce :: TorresNG&#39;s Blog</title>
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content=""/>
<meta name="keywords" content=""/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="/posts/understanding_mapreduce/" />


<link rel="stylesheet" href="/assets/style.css">


<link rel="stylesheet" href="/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/img/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="/img/favicon.png">


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="理解MapReduce"/>
<meta name="twitter:description" content=""/>



<meta property="og:title" content="理解MapReduce" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/understanding_mapreduce/" />
<meta property="article:published_time" content="2019-07-01T21:18:06&#43;08:00"/>
<meta property="article:modified_time" content="2019-07-01T21:18:06&#43;08:00"/><meta property="og:site_name" content="TorresNG&#39;s Blog" />






  </head>
  <body class="dark-theme">
    <div class="container">
      <header class="header">
  <span class="header__inner">
    <a href="/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" width="44" height="44" viewBox="0 0 44 44">
  <polyline fill="none" stroke="#000" stroke-width="2" points="15 8 29.729 22.382 15 35.367"/>
</svg>
</span>
    <span class="logo__text">Learning | Creating | Shareing</span>
    <span class="logo__cursor"></span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="/showcase">Showcase</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none"/>
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>

      </span>
    </span>
  </span>
</header>


      <div class="content">
        
  <div class="post">
    <h2 class="post-title"><a href="/posts/understanding_mapreduce/">理解MapReduce</a></h2>
    <div class="post-meta">
      
        <span class="post-date">
            2019-07-01
        </span>
      
      
      
    </div>

    

    

    <div class="post-content">
      <h2 id="概念">概念</h2>

<p>假如我們有一份很大的數據需要處理，只用單進程單線程需要大量的運行時間，為了減少執行時間，我們可以用多進程多線程并發執行，把一個大的數據划分為獨立較小的數據，然後交給這些進程獨立執行，當這些較小的數據處理完後，我們可以很容易把它們合并成最終結果，這是典型的分治算法，也是MapReduce的主要思想。</p>

<p>當然MapReduce要處理的是大數據的問題，需要解決的事比上面遠大得多。因為單台計算機最後也會出現性能瓶頸，不單擴展單台計算機比較困難且昂貴，而且當單台計算機Crash後，之前所處理的數據全都白費了，所以MapReduce的架構是主要是為了能在多個計算機上實現并行化計算。通過MapReduce可以在大量普通的計算機上實現高性能計算，而且具有可擴展性和高可性的特點。</p>

<p>MapReduce執行部分簡單可以分為單個<strong>Master</strong>和多個<strong>Worker</strong>，<strong>Master</strong>就像公司里的Leader，負責管理，調度和分配任務給小弟，而<strong>Worker</strong>就是拼了命工作的那些小弟，為了防了單台計算機，這些<strong>Worker</strong>分布在集群中不同的計算機上執行，當一個計算機Crash後，<strong>Master</strong>可以將那台計算機所執行的任務分配給其他<strong>Worker</strong>，這樣實現了高可用。那Master死後怎麼辦？那只能呵呵呵了，當然有各種方式可以解決，其中一種就是通知用戶<strong>Master</strong> Crash了，讓用戶決定處理方法。</p>

<p>金<img src="/media/understanding_mapreduce/Google_MapReduce.jpg" alt="Google Reduce" /></p>

<h2 id="map-和-reduce">map 和 reduce</h2>

<p>通過MapReduce，我們可以不用處理分布式上遇到的各種問題，MapReduce為我們處理了并行編程中分布存儲、工作調度、負載均衡、容錯處理及網絡通信等複雜問題，MapReduce任務分為兩個阶段：<strong>map阶段</strong>和<strong>reduce阶段</strong>。每阶段都以鍵值對作為輸入和輸出，其類型由程序員選擇。程序員還需要寫兩個函數：<strong>map函數</strong>和<strong>reduce函數</strong>。<strong>map函數</strong>負責把每個分片進行處理，<strong>reduce函數</strong>負責把map處理後的結果汇總起來。需要注意的是，用MapReduce來處理的數據集（或任務）必須具備這樣的特點：待處理的數據集可以分解成計多小的數據集，而且每一個小數據集都可以完全并行地處理。</p>

<h2 id="分片">分片</h2>

<p>Hadoop將MapReduce的輸入數據划分成等長的小數據塊，稱為<strong>輸入分片</strong>或<strong>分片</strong>。Hadoop為每個分片构建一個map任務，并由該任務來運行用戶自定義的<strong>map函數</strong>從而處理分片中的每條記錄。</p>

<p>最佳分片的大小應該與塊大小相同：因為它是確保可以存儲在單個節點上的最大輸入塊的大小。如果分片跨越兩個數據塊，那麼對於任何一個 HDFS 節點，基本上都不可能同時存儲這兩個數據塊。</p>

<h2 id="數據流">數據流</h2>

<p>map任務將其輸出寫入本地硬盤，而非HDFS。因為map的輸出是中間結果，如果把它存儲在HDFS中并實現備份，難免有些小題大做。如果運行map任務的節點在將map中間結果傳送給reduce任務之前失敗，Hadoop將在另一個節點上重新運行這個map任務以再次构建map中結果。</p>

<p>而reduce任務不具備數據本地化的優勢，單個reduce任務的輸入通常來自於所有mapper的輸出。reduce的輸出通常存儲在HDFS中以實現可靠存儲，對於reduce輸出的每個HDFS塊，第一個複本存儲在本地節點上，其他複本出於可靠性考慮存儲在其他機架的節點中。因此，將reduce的輸出寫入HDFS確實需要占用網絡帶寬，但這與正常的HDFS管線寫入的消耗一樣。</p>

<p>如果有好多個reduce任務，每個map任務就會針對輸出進行分區，即為每個reduce任務建一個分區。每個分區有許多鍵（及其對應的值），但每個鍵對應的鍵-值對記錄都在同一分區中。分區可由用戶定義的分區函數控制，但通常用默認的partitioner通過哈希函數來分區，很高效。map任務和reduce任務之間的數據流稱為<strong>shuffle</strong>，因為每個reduce任務的輸入都來自許多map任務。</p>

<p><img src="/media/understanding_mapreduce/MapReduce_data_flow_with multiple_reduce_tasks.png" alt="Google Reduce" /></p>

<p>當數據處理可以完全并行（即無需shuffle時），可能會出現無reduce任務的情況。在這種情況下，唯一的非本地節點數據傳輸是map任務將結果寫入HDFS。</p>

<p><img src="/media/understanding_mapreduce/MapReduce_data_flow_with_no_reduce_tasks.png" alt="Google Reduce" /></p>

<h2 id="combiner函數">combiner函數</h2>

<p>集群上的可用帶寬限制了MapReduce作業數量，因此䀆量避免map和reduce任務之間的數據傳輸是有利的（例如傳輸較小的數據）。Hadoop允許用戶針對map任務的輸出指定一個<strong>combiner</strong>（就像mapper和reduce一樣），combiner函數的輸出作為reduce函數的輸入。由於cmobiner屬於優化方案，所以Hadoop無法確定要對一個指定的map任務輸出記錄調用多少次combiner（如果需要）。換而言之，不管調用combiner多少次，0次，1次或多次，reducer的輸出結果都是一樣的。</p>

<h2 id="運行代碼">運行代碼</h2>

<p>安裝 Java 和 Hadoop 可以參考我另一篇文章 <a href="http://www.torresng.com/posts/install_hadoop_2.7_in_centos_7/">Install Hadoop 2.7 in CentOS 7</a>。</p>

<p>這里我用 Hadoop權威指南 第二章的代碼做測試，源代碼可以從<a href="https://github.com/tomwhite/hadoop-book">這里下載</a>。這個代碼計算每年的最高氣溫。</p>

<p>用 git 下載源碼下來後，將數據 sample.txt 複製到源碼路徑下，然後編譯運行。最後輸出結果。</p>

<pre><code class="language-shell">$ git clone https://github.com/tomwhite/hadoop-book.git
$ cd hadoop-book
$ cp input/ncdc/sample.txt ch02-mr-intro/src/main/java/
$ cd ch02-mr-intro/src/main/java/
$ javac MaxTemperature.java                                                          
Note: MaxTemperature.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
$ java MaxTemperature sample.txt output
$ cat output/*
1949    111
1950    22
</code></pre>

<h3 id="代碼">代碼</h3>

<h4 id="用例數據">用例數據</h4>

<p>sample.txt</p>

<pre><code>0067011990999991950051507004+68750+023550FM-12+038299999V0203301N00671220001CN9999999N9+00001+99999999999
0043011990999991950051512004+68750+023550FM-12+038299999V0203201N00671220001CN9999999N9+00221+99999999999
0043011990999991950051518004+68750+023550FM-12+038299999V0203201N00261220001CN9999999N9-00111+99999999999
0043012650999991949032412004+62300+010750FM-12+048599999V0202701N00461220001CN0500001N9+01111+99999999999
0043012650999991949032418004+62300+010750FM-12+048599999V0202701N00461220001CN0500001N9+00781+99999999999
</code></pre>

<p>每行的第15個字符到第19個字符為年份，第87到第92個字符為溫度，第93個字符為質量代碼。</p>

<h4 id="map函數">map函數</h4>

<p>MaxTemperatureMapper.java</p>

<pre><code class="language-java">
import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class MaxTemperatureMapper
  extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

  private static final int MISSING = 9999;
  
  @Override
  public void map(LongWritable key, Text value, Context context)
      throws IOException, InterruptedException {
    
    String line = value.toString();
    String year = line.substring(15, 19);
    int airTemperature;
    if (line.charAt(87) == '+') { // parseInt doesn't like leading plus signs
      airTemperature = Integer.parseInt(line.substring(88, 92));
    } else {
      airTemperature = Integer.parseInt(line.substring(87, 92));
    }
    String quality = line.substring(92, 93);
    if (airTemperature != MISSING &amp;&amp; quality.matches(&quot;[01459]&quot;)) {
      context.write(new Text(year), new IntWritable(airTemperature));
    }
  }
}
</code></pre>

<p>這個 Mapper 類是一個泛型類型，它有四個形參類型，分別指定 map 函數的輸入鍵、輸入值、輸出鍵和輸出的類型。這個例子中，輸入鍵是一個長整數偏移量，輸入值是一行文本，輸出鍵是年份，輸出值是氣溫（整數）。</p>

<h4 id="reduce函數">reduce函數</h4>

<p>MaxTemperatureReducer.java</p>

<pre><code class="language-java">import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class MaxTemperatureReducer
  extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
  
  @Override
  public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
      Context context)
      throws IOException, InterruptedException {
    
    int maxValue = Integer.MIN_VALUE;
    for (IntWritable value : values) {
      maxValue = Math.max(maxValue, value.get());
    }
    context.write(key, new IntWritable(maxValue));
  }
}
</code></pre>

<p>同樣，reduce 函數也有四個形式參數類型用於指定輸入和輸出類型。reduce 函數的輸入類型必須匹配 map 函數的輸出類型：即 Text 類型和 IntWritable 類型。</p>

<h4 id="負責運行-mapreduce-作業">負責運行 MapReduce 作業</h4>

<p>MaxTemperature.java</p>

<pre><code class="language-java">import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class MaxTemperature {

  public static void main(String[] args) throws Exception {
    if (args.length != 2) {
      System.err.println(&quot;Usage: MaxTemperature &lt;input path&gt; &lt;output path&gt;&quot;);
      System.exit(-1);
    }
    
    Job job = new Job();
    job.setJarByClass(MaxTemperature.class);
    job.setJobName(&quot;Max temperature&quot;);

    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    job.setMapperClass(MaxTemperatureMapper.class);
    job.setReducerClass(MaxTemperatureReducer.class);

    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}
</code></pre>

<p>通過 <strong>setMapperClass()</strong> 和 <strong>setReducerClass()</strong> 方法指定要用的 map 類型和  reduce 類型。</p>

<p><strong>setOutputKeyClass()</strong> 和 <strong>setOutputValueClass()</strong> 方法控制 reduce 函數的輸出類型，并且必須和 Reduce 類產生的相匹配。map 函數的輸出類型默認情況下和 reduce 函數是相同的，因此如果 mapper 產生出和 reducer 相同的類型時（如同本例所示），不需要單獨設置。否則，必須通過 <strong>setMapOutputKeyClass()</strong> 和 <strong>setMapOutputValueClass()</strong> 方法來設置 map 函數的輸出類型。</p>

<p>輸入的類型通過輸入格式來控制，我們的例子中沒有設置，因為使用的是默認的 <strong>TextInputFormat</strong>（文字輸入格式）。</p>
    </div>
    
      <div class="pagination">
        <div class="pagination__title">
          <span class="pagination__title-h">Read other posts</span>
          <hr />
        </div>
        <div class="pagination__buttons">
          
          
            <span class="button next">
              <a href="/posts/install_hadoop_2.7_in_centos_7/">
                <span class="button__text">Install Hadoop 2.7 in CentOS 7</span>
                <span class="button__icon">→</span>
              </a>
            </span>
          
        </div>
      </div>
    

    

    </div>

      </div>

      
        <footer class="footer">
  <div class="footer__inner">
    
      <a href="/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" width="44" height="44" viewBox="0 0 44 44">
  <polyline fill="none" stroke="#000" stroke-width="2" points="15 8 29.729 22.382 15 35.367"/>
</svg>
</span>
    <span class="logo__text">Learning | Creating | Shareing</span>
    <span class="logo__cursor"></span>
  
</a>

      <div class="copyright">
        <span>© 2019 Powered by <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a></span>
        <span>Theme created by <a href="https://twitter.com/panr" target="_blank" rel="noopener">panr</a></span>
      </div>
    
  </div>
</footer>

<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>


      
    </div>

    
  </body>
</html>
